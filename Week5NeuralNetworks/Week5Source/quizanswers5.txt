1. The following question will ask you about the below neural network,
 where we set w0 = -5, w1 = 2, w2 = -1, and w3 = 3. x1, x2,
 and x3 represent input neurons, and y represents the output neuron.

What value will this network compute for y given inputs x1 = 3, x2 = 2, and x3 = 4
if we use a step activation function? What if we use a ReLU activation function?

1- g(-5 + 2x1 + -1x2 + 3x3)
   g(-5 + 2.3 + -1.2 + 3.4) = 11 = 1 in step activation.
   
   1- No.
   2- No.
   3-
   4-
   5- This is the only result that makes sense, 1 for step activation, 11 for relu.
   6- No.
   7- No
   8- No.

2- How many total weights (including biases)
 will there be for a fully connected neural network with a single input layer with
 3 units, a single hidden layer with 5 units, and a single output layer with 4 units?

   5x3 = 15 weights(without biases) + 5x4 = 35 weights
   Bias terms = 5 + 4 = 9 bias. 35 + 9 = 44.

3- There needs to be just one output, since it will clasify the voice to just one person, but
   it will recieve multiple speech samples. 

4- [[16, 12], [32, 28]]


















